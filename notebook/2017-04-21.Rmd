# 21 April 2017

```{r setup, echo=FALSE, cache=FALSE}
### This chunk can be deleted from any entry that lacks R code

# Knitr options. Note that these mean:
#   - All output will be cached. This is desireable in case code/data changes in the 
#     future; but it means that all chunks should be labeled for reliable behavior. 
#     DEPENDENCIES ACROSS CODE CHUNKS MAY BE AN ISSUE.
#   - R code will run in the project root directory
knitr::opts_chunk$set(comment = '', cache = TRUE)
knitr::opts_knit$set(root.dir = "..")
```
```{r setup2, echo=FALSE, message=FALSE, cache=TRUE}
### This chunk can be deleted from any entry that lacks R code

# Load the project. For some reason it has to be in a separate chunck.
library(ProjectTemplate)
load.project()
```

## Data munging
Realizing that I need to re-use the `seedlings1` data from last time, I see that I should start to use the `munge` directory for key derived data. I therefore ned to give it a more meaningful name; how about `Ler_seeds_gen1`. I'll also add some more information about home and away

The code for doing this is in `munge/01-Ler-seed-gen1.R`

## Ler fecundity
### Reanalyze effective seed number

In the process of doing this I discovered that last time I failed to double the dispersing seeds in the effective seed number calculation. So let's redo the graph and table.

Plot the distributions:
```{r sdlgHist1}
ggplot(Ler_seed_gen1, aes(x = eff_sd_no, fill = as.factor(Density))) + 
  geom_histogram(binwidth = 50)
```

(of course, stacked histograms aren't great, but it gives the general idea).

Now look at the mean and variance across pots:
```{r sdlgTable1}
kable(group_by(Ler_seed_gen1, Density) %>% 
        summarise(Mean = mean(eff_sd_no), Variance = var(eff_sd_no)),
      caption = paste("Mean and variance across pots of effective seed number",
                      "in treatments B and C of Ler generation 1")
      )
```

This changes the quantitative mean:variance ratios:

- For isolated plants, the variance is about `r round(3443/134)` times the mean. Compared with Poisson, this is huge!
- As we go from a density of 1 to 50, the seeds per plant drops by a factor of `r round(134/(348/50))`, from 134 to about `r round(348/50)`.
- If the among-pot variance at high density was caused by iid variation in individual seed production, the among individual variance would need to be 21363/50, or about `r round(21363/50)`. 
    - This is a `r round((21363/348) / (3443/134))`-fold increase in the variance:mean ratio
    - It seems that, to acheive this among-individual variance, almost all the seeds in the high density plots would need to come from one or two individuals--and whether the among-successful-individual variance required is consistent with what we see in isolated pots remains an open question. We would need to assume something like a lognormal distribution among individuals to get at this.

### Home seeds as proxy
Now lets look at how well home seeds predicts total effective seeds:
```{r plot_home_eff}
qplot(home, eff_sd_no, data = Ler_seed_gen1, 
      group = as.factor(Density), colour = as.factor(Density),
      xlab = "Number of seedlings in home pot", 
      ylab = "Effective seed number"
      ) + 
  geom_smooth(method = "lm")
summary(lm(eff_sd_no ~ home * as.factor(Density), data = Ler_seed_gen1))
```

There's no evidence for differences among the two pots, so fortunately we can merge them:
```{r plot_home_eff2}
qplot(home, eff_sd_no, data = Ler_seed_gen1, 
      xlab = "Number of seedlings in home pot", 
      ylab = "Effective seed number"
      ) + 
  geom_smooth(method = "lm")
summary(lm(eff_sd_no ~ home, data = Ler_seed_gen1))
```

Fortunately the relationship is linear and independent of density (although with only two density treatments these conclustions are not super robust). And while we explain 78% of the variance there is still some scatter: the home pot seeds represents "measurement error" relative to the effective seed number (although the effective seed number itself seems pretty stochastic, as the fraction of seeds dispersing is pretty stochastic). However, it's the best we have.
