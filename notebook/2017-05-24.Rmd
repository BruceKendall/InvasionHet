# 19 May 2027
```{r setup, echo=FALSE, cache=FALSE}
#######################################################################################
### This chunk can be deleted from any entry that lacks R code                      ###
#######################################################################################
# Note that the cache = FALSE is needed to prevent ProjectTemplate errors in the next 
#   chunk. This is unfortunate as it slows build of the full notebook.

# Knitr options. Note that these mean:
#   - All output will be cached. This is desireable in case code/data changes in the 
#     future; but it means that all chunks should be labeled for reliable behavior. 
#     DEPENDENCIES ACROSS CODE CHUNKS MAY BE AN ISSUE.
#   - R code will run in the project root directory
knitr::opts_chunk$set(comment = '', cache = TRUE)
knitr::opts_knit$set(root.dir = "..")
```
```{r setup2, echo=FALSE, message=FALSE, cache=TRUE}
#######################################################################################
### This chunk can be deleted from any entry that lacks R code                      ###
### Set cache=FALSE during the day if you are changing the project environment;     ###
###   set it back to TRUE at the end of the day to ensure that rebuilds don't do    ###
###   unneccesary project loads.                                                    ###
#######################################################################################

# Load the project. For some reason it has to be in a separate chunck.
library(ProjectTemplate)
load.project()
```

## Reboot Ler spread rates

(Rerun of analyses from 5 and 8 May)

Look at trends by rep:
```{r speed_trends, message=FALSE}
ggplot(LerC_spread, aes(x = Generation, y = speed, color = Rep)) +
  geom_point(position = "jitter") + 
  geom_smooth(method = "lm", se = FALSE) + 
  facet_wrap(~Gap)
ggplot(LerC_spread, aes(x = Generation, y = speed)) +
  geom_point(position = "jitter") + 
  geom_smooth() + 
  facet_wrap(~Gap)
ggplot(LerC_spread, aes(x = Generation, y = speed)) +
  geom_point(position = "jitter") + 
  geom_smooth(method = "gam", method.args = list(k = 4)) + 
  facet_wrap(~Gap)
summary(lm(speed ~ Generation, data = filter(LerC_spread, Gap == "0p")))
library(mgcv)
summary(gam(speed ~ s(Generation, k = 4), data = filter(LerC_spread, Gap == "0p")))
plot(gam(speed ~ s(Generation, k = 4), data = filter(LerC_spread, Gap == "0p")))
anova(gam(speed ~ s(Generation, k = 4), data = filter(LerC_spread, Gap == "0p")), 
      gam(speed ~ Generation, data = filter(LerC_spread, Gap == "0p")),
      test = "Chisq") 
```
This replicates the prior analysis exactly.

Now look at the autocorrelation and interaction analysis from 8 May:
```{r Ler_speed_mod3}
m13 <- lm(speed ~ poly(Generation, 2) * Rep + speed_m1, 
          data = filter(LerC_spread, Gap == "0p"))
summary(m13)
car::Anova(m13)
```
Drop the interaction:
```{r Ler_speed_mod4}
m14 <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
          data = filter(LerC_spread, Gap == "0p"))
summary(m14)
car::Anova(m14)
```
So, in conclusion: weak evidence for among-Rep differences in means, but strong evidence for negative autocorrelation. Note that this autocorrelation should act to slow the rate at which the variance in cumulative spread increases with time.

Let's check out the other landscapes:
```{r Ler_speed_gaps}
m24 <- lm(speed ~ Gen + Rep + speed_m1, 
          data = filter(LerC_spread, Gap == "1p"))
m34 <- lm(speed ~ Gen + Rep + speed_m1, 
          data = filter(LerC_spread, Gap == "2p"))
m44 <- lm(speed ~ Gen + Rep + speed_m1, 
          data = filter(LerC_spread, Gap == "3p"))
summary(m24)
summary(m34)
summary(m44)
car::Anova(m24)
car::Anova(m34)
car::Anova(m44)
```
Nothing to see here, folks!

The pattern of autocorrelation should, I think, fall into the category of something that we want the model to reproduce.

And fortunately, nothing has changed from the prior analysis.

### Ler Cumulative spread
And finally double check the cumulative spread plots:

Let's calculate the means and variances of cumulative spread:
```{r cum_spread_stats}
cum_spread_stats <- group_by(LerC_spread, Gap, Gen, Generation) %>%
  summarise(mean_spread = mean(Furthest),
            var_spread = var(Furthest),
            CV_spread = sqrt(var_spread)/mean_spread
  )
```

And now plot the results:
```{r plot_spread_stats}
ggplot(aes(x = Generation, y = mean_spread, color = Gap), data = cum_spread_stats) +
  geom_point() + geom_smooth(method = "lm")
ggplot(aes(x = Generation, y = var_spread, color = Gap), data = cum_spread_stats) +
  geom_point() + geom_line()
ggplot(aes(x = Generation, y = CV_spread, color = Gap), data = cum_spread_stats) +
  geom_point() + geom_line()
```
This looks just like the previous results---repeating my previous summary, 

> The linear approximation to mean spread is pretty good, although we see a dip in generation 6, as expected from the reduced seed production, and even without gen 6, the continuous runways seem to be decelerating. The ranking between landscapes makes sense. The variances are rather more over the map, although we don't have confidence intervals on them. But exept for 1-pot gaps, we can squint and imagine that the variances are linear in time. Note, however, that with only 6 generations we're not going to easily detect nonlinearities. I don't know that the CVs tell us much.

It really does seem relevant to do the bootstrapping, to see whether the (rather nonsystematic) patterns in the cumulative variance vs. time are real.

## Reboot spread analysis of evolution experiments
(From 10 May)

Let's calculate the means and variances of cumulative spread:
```{r cum_spread_stats_RIL}
cum_spread_stats <- group_by(RIL_spread, Treatment, Gap, Gen, Generation) %>%
  summarise(mean_spread = mean(Furthest),
            var_spread = var(Furthest),
            CV_spread = sqrt(var_spread)/mean_spread
  )
```

And now plot the results:
```{r plot_spread_stats_RIL}
ggplot(aes(x = Generation, y = mean_spread, color = Treatment), data = cum_spread_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
ggplot(aes(x = Generation, y = var_spread, color = Treatment), data = cum_spread_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
ggplot(aes(x = Generation, y = CV_spread, color = Treatment), data = cum_spread_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
```

The patterns in the mean are probably not overly distinguishable from linear, although I'd want to see CIs.

Let's look at per-generation spread.

```{r speed_stats_RIL}
speed_stats <- group_by(RIL_spread, Treatment, Gap, Gen, Generation) %>%
  summarise(mean_spread = mean(speed),
            var_spread = var(speed),
            CV_spread = sqrt(var_spread)/mean_spread
  )
```

And now plot the results:
```{r plot_speed_stats_RIL}
ggplot(aes(x = Generation, y = mean_spread, color = Treatment), data = speed_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
ggplot(aes(x = Generation, y = var_spread, color = Treatment), data = speed_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
ggplot(aes(x = Generation, y = CV_spread, color = Treatment), data = speed_stats) +
  geom_point() + geom_line() + facet_wrap(~ Gap)
```
These plots look pretty similar (though not identical) to the second pass in the original analysis (after I dropped the problematic rep).

In 0p and 1p, the treatments look very similar. But I bet there will be differences in the autocorrelation structure. Let's fit some models.

```{r RILL_speed_mod}
m1_0NO <- lm(speed ~ Gen + Rep + speed_m1, data = filter(RIL_spread, Gap == "0p", Treatment == "NO"))
summary(m1_0NO)
car::Anova(m1_0NO)
m1_0YES <- lm(speed ~ Gen + Rep + speed_m1, data = filter(RIL_spread, Gap == "0p", Treatment == "YES"))
summary(m1_0YES)
car::Anova(m1_0YES)
```

This is getting different. Let's try some models with continuous Generation:
```{r RILL_speed_mod2}
m1_0NO <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
             data = filter(RIL_spread, Gap == "0p", Treatment == "NO"))
summary(m1_0NO)
car::Anova(m1_0NO)
m1_0YES <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
              data = filter(RIL_spread, Gap == "0p", Treatment == "YES"))
summary(m1_0YES)
car::Anova(m1_0YES)
m1_0YES <- lm(speed ~ Generation + Rep + speed_m1, 
              data = filter(RIL_spread, Gap == "0p", Treatment == "YES"))
summary(m1_0YES)
car::Anova(m1_0YES)
```
So we get that the evolution treatment has negative autocorrelation but no time effect, whereas the no-evolution treatment has a quadratic time effect but no autocorrelation.

Let's look at the rest of the landscapes.

```{r RILL_speed_mod1p}
m2_0NO <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
             data = filter(RIL_spread, Gap == "1p", Treatment == "NO"))
summary(m2_0NO)
car::Anova(m2_0NO)
m2_0YES <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
              data = filter(RIL_spread, Gap == "1p", Treatment == "YES"))
summary(m2_0YES)
car::Anova(m2_0YES)
```

```{r RILL_speed_mod2p}
m2_0NO <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
             data = filter(RIL_spread, Gap == "2p", Treatment == "NO"))
summary(m2_0NO)
car::Anova(m2_0NO)
m2_0YES <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
              data = filter(RIL_spread, Gap == "2p", Treatment == "YES"))
summary(m2_0YES)
car::Anova(m2_0YES)
```

```{r RILL_speed_mod3p}
m2_0NO <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
             data = filter(RIL_spread, Gap == "3p", Treatment == "NO"))
summary(m2_0NO)
car::Anova(m2_0NO)
m2_0YES <- lm(speed ~ poly(Generation, 2) + Rep + speed_m1, 
              data = filter(RIL_spread, Gap == "3p", Treatment == "YES"))
summary(m2_0YES)
car::Anova(m2_0YES)
```
For evolution YES, we have:

- Autocorrelation in gaps 0, 2, 3
- Gen effects in gap 2

For evolution NO, we have:

- Autocorrelation in gaps 1
- Gen effects in gaps 0, 1 

Well, so what? This will require a bit of puzzling.

One thing to notice: the per-generation variance in spread is, on average, higher in the evolution treatment across all landscapes. However, this translates to a higher variance in cumulative variance only in landscapes 1p and 3p (and I'm guessing the CI on 3p is large). 1p is the landscape with no significant autocorrelation in the evolution treatment. However, 3p has a large negative AC.

## Modeling
OK, here's the part I've been dreading: reconstructing the models from almost 2 years ago...

Well, the first thing I found noodling around is some models of Ler DD fecundity in `LerSims`. But then I got distracted thinking about sources of stochasticity. First, we actually have estimates of demographic stochasticity in the RIL density experiments, as siliques are counted on multiple plants per pot. See `fecundity_variability`. I can't remember whether any of the silique counts in the populations actually account for them by individual---I suspect not.

Second, there are two aspects of "environmental stochasticity." The first is location of the pot within the greenhouse, which could affect both temperature/light and exposure to pests. In this case, we would expect nearby pots to have similar residuals. We don't have a map of where pots were, but we do know that pots in the same runway were close to one another---thus we'd expect, within a given generation, less variability among pots in a runway than overall across all runways.

However, another source is inconsistency in the watering treatment, which affects both the total number of seeds released per silique (effective fecundity) as well as the dispersal kernel (in addition to creating heterogeneous disperpersal, this will create extra variabiity in the number of seeds staying in the home pot, which is our measure of fecundity in many cases). This could easily vary from pot to pot within a runway.
