<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Parameter Estimation on Project notebook for the Invasion Heterogeneity project</title>
    <link>/InvasionHet/categories/parameter-estimation/</link>
    <description>Recent content in Parameter Estimation on Project notebook for the Invasion Heterogeneity project</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/InvasionHet/categories/parameter-estimation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Ler sims, and RIL parameterization plans</title>
      <link>/InvasionHet/2019/05/22/ler-sims-and-ril-parameterization-plans/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/05/22/ler-sims-and-ril-parameterization-plans/</guid>
      <description>Ler analysis I’ve got the complete set of gen 6 spread distances now. For a few of them there are some crazy high dispersal distances, so it can be easier to trim the most extreme ones
options(tibble.print_max = Inf) Ler_spread_stats %&amp;gt;% group_by(Gap, DS, ES, KS, SS) %&amp;gt;% summarize(Mean = mean(Max_Dist), Var = var(Max_Dist)) # A tibble: 64 x 7 # Groups: Gap, DS, ES, KS [?] Gap DS ES KS SS Mean Var &amp;lt;int&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; 1 0 FALSE FALSE FALSE FALSE 14 0 2 0 FALSE FALSE FALSE TRUE 15.</description>
    </item>
    
    <item>
      <title>Beta-binomial distribution of fraction dispersing</title>
      <link>/InvasionHet/2019/05/18/beta-binomial-distribution-of-fraction-dispersing/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/05/18/beta-binomial-distribution-of-fraction-dispersing/</guid>
      <description>I never looked at how to calculate the parameters for the fraction dispersing. The trick may be the betabinomial function in the VGAM library.
The first step is to amalgamate all the dispersing seeds from disperseLer:
nondispersers &amp;lt;- subset(disperseLer, Pot == 0, c(&amp;quot;ID&amp;quot;, &amp;quot;Seedlings&amp;quot;)) dispersers &amp;lt;- filter(disperseLer, Pot == 1) %&amp;gt;% group_by(ID) %&amp;gt;% summarise(dispersers = sum(Seedlings)) disperse_num &amp;lt;- merge(nondispersers, dispersers) names(disperse_num)[2] &amp;lt;- &amp;quot;nondispersers&amp;quot; disperse_num$dispersers &amp;lt;- round(2 * disperse_num$dispersers) So now we make an intercept-only model with vgam.</description>
    </item>
    
    <item>
      <title>Estimating seed production with mixed effects</title>
      <link>/InvasionHet/2019/05/18/estimating-seed-production-with-mixed-effects/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/05/18/estimating-seed-production-with-mixed-effects/</guid>
      <description>Warning: I need to see what the “seeds” here are—they may only be home pot seeds, in which case I need to adjust the intercept (and perhaps its variance) by the fraction dispersing from the dispersal analyses.
Returning to parameter estimation for density dependent seed production… This is based primarily on the post from 5 June 2017. The main change is that I want to use mixed effects to estimate the variance due to a random effect of generation, as well as a random effect of replicate within generation.</description>
    </item>
    
    <item>
      <title>Final final dispersal</title>
      <link>/InvasionHet/2019/04/26/final-final-dispersal/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/26/final-final-dispersal/</guid>
      <description>A few things.
On further reflection, I think that I do indeed want to use multivariate normal for generating dispersal kernels. I need to find the “odd” fit and drop that from the analysis For “fitall,” I need to check the other distributions; maybe one of them is better.  Eliminate odd fit First replicate yesterday’s analysis and print them out with IDs:
disperseLer2 &amp;lt;- filter(disperseLer, ID != &amp;quot;79_0&amp;quot;, ID !</description>
    </item>
    
    <item>
      <title>Finalizing dispersal (for now)</title>
      <link>/InvasionHet/2019/04/25/finalizing-dispersal-for-now/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/25/finalizing-dispersal-for-now/</guid>
      <description>Time is running short for the Davis presentation. So, at least for now, I will accept the generalized gamma distribution and the subset of data to which it fits, and move forward with creating the model.
What I need to do:
 Double check that that the replicate-specific model fits better than a single set of parameters for all the data Plot the resulting dispersal kernels Plot the patterns of covariance in parameters Quantify the meta-distribution of parameters, to use in the model  Evidence of heterogeneity The replicates to which gengamma didn’t fit were 79_0 and 90_1.</description>
    </item>
    
    <item>
      <title>Robustifying the generalized gamma fit</title>
      <link>/InvasionHet/2019/04/22/robustifying-the-generalized-gamma-fit/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/22/robustifying-the-generalized-gamma-fit/</guid>
      <description>I’m still a bit concerned about the generalized gamma, for two reasons: am I getting good enough starting values; and why do I get errors in the function evaluation.
For the first, my previous work on moments was not helpful. So I think that the only robust approach is to start from lots of random start values. However, that brings up the second issue of rather frequent failures. I think the issue is that flexsurv is not quite standard in how it deals with edge conditions.</description>
    </item>
    
    <item>
      <title>A general moment generator</title>
      <link>/InvasionHet/2019/04/19/a-general-moment-generator/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/19/a-general-moment-generator/</guid>
      <description>I’m close to having the formulas needed to create an “mgengamma”, allowing us to use the method of moments to fit that distribution. But that doesn’t get us closer to a broader problem: the need to get good start values for truncated distributions, as well as, potentially, bespoke distributions such as 2Dt.
For this, I think I can write a function to generate random numbers under the distribution, then calculate the moments and return them in a form useful to the moment matching algorithm.</description>
    </item>
    
    <item>
      <title>Moments of generalized gamma</title>
      <link>/InvasionHet/2019/04/18/moments-of-generalized-gamma/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/18/moments-of-generalized-gamma/</guid>
      <description>The fact that we are still having trouble fitting the generalized gamma suggests that we should move to a method of moments. Because the distribution has three parameters we need three moments. Wikipedia gives the mean and variance, but not the skew; and anywy it may be easier to use raw moments.
Stacy and Mihram (1965: Technometrics 7, 349-58) give an expression for the raw moments:
\[ E(X^r) = \frac{a^r \Gamma \left[\nu + r/p \right]}{\Gamma(\nu)}.</description>
    </item>
    
    <item>
      <title>Fitting the distributions</title>
      <link>/InvasionHet/2019/04/17/fitting-the-distributions/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/17/fitting-the-distributions/</guid>
      <description>I’ve written the code to automatically fit all the untruncated distributions. Here it is, in helpers.R:
fit_dispersal_untruncated  function(dispersal_data, zero = 7, model_list = c(&amp;quot;hnorm&amp;quot;, &amp;quot;exp&amp;quot;, &amp;quot;lnorm&amp;quot;, &amp;quot;gamma&amp;quot;, &amp;quot;weibull&amp;quot;, &amp;quot;invgauss&amp;quot;, &amp;quot;logis&amp;quot;, &amp;quot;invgamma&amp;quot;)) { # Fit untruncated dispersal models to data # dispersal_data must be a data frame containing columns # ID, Density, Siliques, Seedlings, Distance # All data in dispersal_data are used in a single fit, so if only a single rep is to # be analyzed, it should be subset outside this function if (&amp;quot;invgauss&amp;quot; %in% model_list) library(actuar) if (&amp;quot;gengamma&amp;quot; %in% model_list) library(flexsurv) cens_data_tble &amp;lt;- cens_dispersal_data(dispersal_data, zero) result &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>Half-normal distribution</title>
      <link>/InvasionHet/2019/04/17/half-normal-distribution/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/17/half-normal-distribution/</guid>
      <description>Last year I wrote a half-normal distribution but didn’t actually test its fitness for fitting the data. So let’s try it out.
Our usual data:
temp &amp;lt;- filter(disperseLer, ID == &amp;quot;100_0&amp;quot;) cens_data &amp;lt;- cens_dispersal_data(temp, 7) Let’s give it a try:
try(fitdistcens(cens_data, &amp;quot;hnorm&amp;quot;)) Error in computing default starting values. Nope, it needs a start value. Fortunately I already provided one in start_params()!
try(fitdistcens(cens_data, &amp;quot;hnorm&amp;quot;, start = start_params(cens_data, &amp;quot;hnorm&amp;quot;))) Fitting of the distribution &amp;#39; hnorm &amp;#39; on censored data by maximum likelihood Parameters: estimate sigma 2.</description>
    </item>
    
    <item>
      <title>Restricting the list of distributions</title>
      <link>/InvasionHet/2019/04/17/restricting-the-list-of-distributions/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2019/04/17/restricting-the-list-of-distributions/</guid>
      <description>I&amp;rsquo;ve just realized that any dispersal distribution that I&amp;rsquo;m actually going to use in the model requires the ability to generate random numbers. Thus, for the &amp;ldquo;custom&amp;rdquo; distributions I&amp;rsquo;d have to write a RNG, which I really don&amp;rsquo;t want to do.
So I think that means ditching the 2Dt, log-sech, and inverse power models.
If the best fit is a truncated distribution then I might need to write a simple wrapper to discard the truncated bit.</description>
    </item>
    
    <item>
      <title>Getting start values from moments</title>
      <link>/InvasionHet/2018/11/29/getting-start-values-form-moments/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/11/29/getting-start-values-form-moments/</guid>
      <description>It is possible to get start values from the matching moments fit. For example:
library(fitdistrplus) Loading required package: MASS Loading required package: survival Loading required package: npsurv Loading required package: lsei library(actuar)  Attaching package: &amp;#39;actuar&amp;#39; The following object is masked from &amp;#39;package:grDevices&amp;#39;: cm x4 &amp;lt;- rpareto(1000, 6, 2) s4 &amp;lt;- fitdist(x4, &amp;quot;pareto&amp;quot;, &amp;quot;mme&amp;quot;, order=c(1, 2), memp=function(x, order) emm(x, order)) s4$estimate  shape scale 9.323582 3.527362  fitdist(x4, &amp;quot;pareto&amp;quot;, start = as.</description>
    </item>
    
    <item>
      <title>Vectorization in fitdistrplus</title>
      <link>/InvasionHet/2018/11/29/vectorization-in-fitdistrplus/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/11/29/vectorization-in-fitdistrplus/</guid>
      <description>I need to figure out how fitdistr is vectorizing the calls to the distribution functions, so I can appropriately build the 2Dt function and think sensibly about the truncated distributions.
The gory details are below, but in summary:
 The parameter values are never vectorized x and q (passed to ddist and pdist respectively) may be vectors x and q may have length zero (which will need to be trapped for when I’m not just passing them on to a predefined distribution) (I don’t know why!</description>
    </item>
    
    <item>
      <title>More on distributions</title>
      <link>/InvasionHet/2018/11/20/more-on-distributions/</link>
      <pubDate>Tue, 20 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/11/20/more-on-distributions/</guid>
      <description>temp &amp;lt;- filter(disperseLer, ID == &amp;quot;100_0&amp;quot;) cens_data &amp;lt;- cens_dispersal_data(temp, 7) Generalized gamma I’ve made a specialized start function for gengamma:
start_gengamma function (x, truncated = FALSE) { if (dim(as.matrix(x))[2] != 2) { stop(&amp;quot;Only interval-censored methods have been developed in start_gengamma&amp;quot;) } dist_list &amp;lt;- c(&amp;quot;lnorm&amp;quot;, &amp;quot;weibull&amp;quot;, &amp;quot;gamma&amp;quot;) n &amp;lt;- length(dist_list) base_fits &amp;lt;- data.frame(dist = dist_list, AIC = numeric(n), p1 = numeric(n), p2 = numeric(n), stringsAsFactors = FALSE) base_starts &amp;lt;- array(list(NULL), n) if (truncated) { stop(&amp;quot;Truncated methods have not yet been developed in start_gengamma&amp;quot;) } for (i in 1:n) { fit &amp;lt;- fitdistcens(x, base_fits$dist[i], base_starts[[i]]) base_fits$AIC[i] &amp;lt;- fit$aic base_fits$p1[i] &amp;lt;- coef(fit)[1] base_fits$p2[i] &amp;lt;- coef(fit)[2] } best &amp;lt;- base_fits[which.</description>
    </item>
    
    <item>
      <title>Likely-looking distributions</title>
      <link>/InvasionHet/2018/11/16/likely-looking-distributions/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/11/16/likely-looking-distributions/</guid>
      <description>Let’s think about which distributions could be good. We know what the (half-)normal, exponential, and log-normal look like.
Nathan et al. (2012) also suggest:
 Exponential power 2Dt Inverse power Logistic Mixture models Inverse Gaussian (Wald) Wiebull Gamma  The scaling factors in Nathan et al. are for two-dimensional dispersal expressed in radial distance (I think). They suggest that this can be converted to a “distance kernel” by multiplying by \(2\pi r\), but that doesn’t seem right for e.</description>
    </item>
    
    <item>
      <title>rmutil and fitdistrplus</title>
      <link>/InvasionHet/2018/10/22/rmutil-and-fitdistrplus/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/10/22/rmutil-and-fitdistrplus/</guid>
      <description>Warning in .check.version(config): Your configuration is compatible with version 0.8 of the ProjectTemplate package. Please run ProjectTemplate::migrate.project() to migrate to the installed version 0.8.2. So the fix I did last week to computegetparam() (to allow “y” as an argument to the distribution functions) does allow fitdist to work (sort of) with the rmutil distributions. However, there can still be failures in estimatation or SE calculation, because there are a number of other ways that the rmutil distributions work differntly from the base distribution functions.</description>
    </item>
    
    <item>
      <title>Working with fitdistrcens</title>
      <link>/InvasionHet/2018/10/18/working-with-fitdistrplus/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/10/18/working-with-fitdistrplus/</guid>
      <description>Warning in .check.version(config): Your configuration is compatible with version 0.8 of the ProjectTemplate package. Please run ProjectTemplate::migrate.project() to migrate to the installed version 0.8.2. So here’s what happens if we try to run fitdistrcens on a non-standard distribution:
library(rmutil) temp &amp;lt;- filter(disperseLer, ID == &amp;quot;100_0&amp;quot;) cens_data &amp;lt;- cens_dispersal_data(temp, 7) try(fitdistcens(cens_data, &amp;quot;ggamma&amp;quot;, start = list(s = 5, m = 4, f = 2)), outFile = stdout()) Error in checkparamlist(arg_startfix$start.arg, arg_startfix$fix.arg, : argument &amp;quot;hasnodefaultval&amp;quot; is missing, with no default Does it work with fitdist, which doesn’t account for the censoring?</description>
    </item>
    
    <item>
      <title>fitdistrplus</title>
      <link>/InvasionHet/2018/10/04/fitdistrplus/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2018/10/04/fitdistrplus/</guid>
      <description>Warning in .check.version(config): Your configuration is compatible with version 0.8 of the ProjectTemplate package. Please run ProjectTemplate::migrate.project() to migrate to the installed version 0.8.2. I’ve modified the helper functions to separate out the creation of the censored data frame from the fitting, and to allow setting the origin. Note that setting zero = 7 only looks at the runway, and allows use of non-truncated distributions when the distribution only has support for non-negative values.</description>
    </item>
    
    <item>
      <title>Revisiting plans, and wrestling with seed stochasticity</title>
      <link>/InvasionHet/2017/10/23/revisiting-plans-and-wrestling-with-seed-stochasticity/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2017/10/23/revisiting-plans-and-wrestling-with-seed-stochasticity/</guid>
      <description>Focus on Ler? As I look at various pieces of the model (which I’ve started to assemble in lib/model.R), I realize that there are a sufficient number of ways in which the RIL data are different (and not yet analyzed) that I may find it challenging to exactly mirror the Ler model. In particular, I’m going to find it rather challenging (I think) to estimate the environmental stochasticity in seed production among generations and replicates.</description>
    </item>
    
    <item>
      <title>Ler kernel heterogeneity</title>
      <link>/InvasionHet/2017/09/22/ler-kernel-heterogeneity/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2017/09/22/ler-kernel-heterogeneity/</guid>
      <description>The next steps in the Ler dispersal analysis are to confirm statistical support for among-rep heterogeneity and see if the kernel parameters are correlated with the fraction dispersing.
Housekeeping Added the functions for the truncated distributions and to fit the models to lib/helpers.R.
 Kernel heterogeneity The total AIC for the rep-specific fits was 58230.28 and 58366.17 for the normal and lognormal models, respectively.
I think that if I pass the whole data set to the analysis function it will combine all the data.</description>
    </item>
    
    <item>
      <title>Fit Ler dispersal kernels</title>
      <link>/InvasionHet/2017/09/19/fit-ler-dispersal-kernels/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2017/09/19/fit-ler-dispersal-kernels/</guid>
      <description>File to load Ler dispersal data Here is the new file data/disperseLer.R:
### Creates the data object disperseLer, representing the Ler dispersal experiment # Get data from Jenn&amp;#39;s file data_dir &amp;lt;- &amp;quot;~/Dropbox/Arabidopsis/analysis&amp;quot; disperseLer &amp;lt;- read.csv(file.path(data_dir, &amp;#39;2013_08_08_Exp1_Spray.csv&amp;#39;), header = TRUE) # Drop the &amp;quot;clipped&amp;quot; treatment disperseLer &amp;lt;- droplevels(subset(disperseLer, new_trt != &amp;quot;clipped&amp;quot;, drop = TRUE)) # Drop the columns with the (irrelevant) info about where the mom pots came from disperseLer &amp;lt;- disperseLer[, -c(1:4, 6)] # Clean up column names names(disperseLer) &amp;lt;- c(&amp;quot;ID&amp;quot;, &amp;quot;Pot&amp;quot;, &amp;quot;Distance&amp;quot;, &amp;quot;Seedlings&amp;quot;, &amp;quot;Siliques&amp;quot;, &amp;quot;Density&amp;quot;, &amp;quot;Treatment&amp;quot;) # Make some factor variables disperseLer$ID &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Fitting dispersal kernels</title>
      <link>/InvasionHet/2017/09/13/fitting-dispersal-kernels/</link>
      <pubDate>Wed, 13 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/InvasionHet/2017/09/13/fitting-dispersal-kernels/</guid>
      <description>Quick looks at dispersal. Lewis et al 2008 show how to calculate empirical moment generating functions, but I’m not sure how useful that is for us. Nathan et al. 2012 has a good review of kernels, but not much statistical info. I found Viana et al. 2016 which suggests fitting the CDF is better than fitting the PDF.
Viana also led my to the fitdistrplus package, which fits standard distributions. I think this is what we need–I was increasinglyl unconfident im my home-rolled fitting routines.</description>
    </item>
    
  </channel>
</rss>